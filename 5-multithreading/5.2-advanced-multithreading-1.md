<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/>

# Advanced Multithreading: Executors, Thread Pools, and Callables

## Table of Contents

1. [Introduction to Production-Level Threading](#introduction-to-production-level-threading)
2. [The Problem with Creating Too Many Threads](#the-problem-with-creating-too-many-threads)
    - [Factory Analogy](#factory-analogy)
    - [Performance Impact](#performance-impact)
3. [Executor Framework](#executor-framework)
    - [Thread Pool Architecture](#thread-pool-architecture)
    - [Types of Thread Pools](#types-of-thread-pools)
    - [Fixed Thread Pool](#fixed-thread-pool)
    - [Cached Thread Pool](#cached-thread-pool)
4. [Runnable vs Callable Interface](#runnable-vs-callable-interface)
    - [Limitations of Runnable](#limitations-of-runnable)
    - [Callable Interface Deep Dive](#callable-interface-deep-dive)
    - [Future and Generic Types](#future-and-generic-types)
5. [Practical Implementation: Merge Sort with Threads](#practical-implementation-merge-sort-with-threads)
    - [Algorithm Overview](#algorithm-overview)
    - [Sequential vs Parallel Approach](#sequential-vs-parallel-approach)
    - [Complete Implementation](#complete-implementation)
6. [Thread Pool Configuration and Best Practices](#thread-pool-configuration-and-best-practices)
    - [ThreadPoolExecutor Parameters](#threadpoolexecutor-parameters)
    - [Monitoring Thread Pools](#monitoring-thread-pools)
    - [Rejection Handling](#rejection-handling)

---

## Introduction to Production-Level Threading

In production environments, creating threads efficiently is crucial for application performance and resource management. This lecture explores advanced threading concepts that move beyond basic thread creation to enterprise-level solutions[^1].

**Key Learning Objectives:**

- Understanding why unlimited thread creation is problematic
- Mastering the Executor framework for thread management
- Learning the Callable interface for threads that return data
- Implementing complex algorithms using thread pools


## The Problem with Creating Too Many Threads

### Factory Analogy

Consider TATA Motors with 1000 production lines creating 1000 cars daily. If demand increases to 5000 cars, would they build 4000 new production lines? No! They would optimize existing lines by working them more efficiently[^1].

```
Traditional Approach (Inefficient):
Task 1 → Create Thread 1 → Execute → Destroy Thread 1
Task 2 → Create Thread 2 → Execute → Destroy Thread 2
Task 3 → Create Thread 3 → Execute → Destroy Thread 3
...
Task N → Create Thread N → Execute → Destroy Thread N

Optimized Approach (Thread Pool):
Tasks 1-1000 → Thread Pool (5 threads) → Reuse → Execute All Tasks
```


### Performance Impact

**Problems with Creating N Threads for N Tasks:**

- **Thread Creation Overhead**: Each thread creation involves system calls and memory allocation
- **Context Switching Cost**: More threads = more context switching = reduced performance
- **Memory Consumption**: Each thread consumes stack memory (typically 1-8MB per thread)
- **Resource Exhaustion**: System limits on maximum threads

**Real-world Example:**

- **Traditional approach** (100,000 tasks with 100,000 threads): 10-20 seconds
- **Thread pool approach** (100,000 tasks with 5 threads): 5 seconds[^1]


## Executor Framework

The Executor framework provides a higher-level abstraction for thread management, separating task submission from thread management details[^2][^6].

### Thread Pool Architecture

```
┌─────────────────────────────────────────┐
│           Executor Framework            │
├─────────────────────────────────────────┤
│  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐│
│  │ W1  │ │ W2  │ │ W3  │ │ W4  │ │ W5  ││ ← Worker Threads
│  └─────┘ └─────┘ └─────┘ └─────┘ └─────┘│
├─────────────────────────────────────────┤
│           Task Queue                    │
│  [Task1][Task2][Task3][Task4][Task5]    │
│  [Task6][Task7][Task8]...               │
└─────────────────────────────────────────┘
```

**Key Components:**

- **Worker Threads**: Fixed number of threads that execute tasks
- **Task Queue**: Queue holding tasks waiting for execution
- **Thread Pool Manager**: Assigns tasks to available threads


### Types of Thread Pools

### Fixed Thread Pool

**Definition**: A thread pool with a fixed number of threads that remain active throughout the application lifecycle[^1][^5].

```java
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class Client {
    public static void main(String[] args) {
        // Creates exactly 5 threads
        ExecutorService ex = Executors.newFixedThreadPool(5);
        
        // Submit 1,000,000 tasks - only 5 threads will handle all
        for(int i = 0; i < 1000000; i++) {
            NumberPrinter np = new NumberPrinter(i);
            ex.execute(np);  // Non-blocking submission
        }
        
        // Shutdown executor when done
        ex.shutdown();
    }
}
```

**Characteristics:**

- **Thread Count**: Fixed at creation time
- **Resource Predictability**: Known memory footprint
- **Most Preferred**: In production environments for predictable load
- **Queue Behavior**: Unlimited queue size (LinkedBlockingQueue)


### Cached Thread Pool

**Definition**: A thread pool that creates new threads as needed and reuses existing threads when available[^1].

```java
ExecutorService ex = Executors.newCachedThreadPool();
// Creates new threads if all existing threads are busy
// Reuses idle threads when available
```

**Characteristics:**

- **Dynamic Size**: No fixed thread limit
- **Thread Lifecycle**: Threads terminate after 60 seconds of inactivity
- **Use Case**: Variable and unpredictable workloads
- **Risk**: Can create unlimited threads under high load

**Comparison Table:**


| Feature | Fixed Thread Pool | Cached Thread Pool |
| :-- | :-- | :-- |
| **Thread Count** | Fixed (specified at creation) | Dynamic (0 to Integer.MAX_VALUE) |
| **Memory Usage** | Predictable | Variable |
| **Performance** | Consistent | Variable based on load |
| **Best For** | Production with known load | Development/testing |
| **Risk Level** | Low | High (potential memory issues) |

## Runnable vs Callable Interface

### Limitations of Runnable

The Runnable interface has significant limitations for complex applications[^3]:

```java
public interface Runnable {
    public void run();  // Cannot return any value
                       // Cannot throw checked exceptions
}
```

**Problems:**

- **No Return Value**: Cannot return computation results
- **No Exception Handling**: Cannot throw checked exceptions
- **Limited Functionality**: Suitable only for fire-and-forget tasks


### Callable Interface Deep Dive

The Callable interface addresses Runnable's limitations by allowing threads to return values[^3][^4].

```java
public interface Callable<T> {
    T call() throws Exception;  // Can return value of type T
                               // Can throw checked exceptions
}
```

**Key Advantages:**

- **Generic Return Type**: Type-safe return values using generics
- **Exception Handling**: Can throw and propagate exceptions
- **Better Integration**: Works seamlessly with Future for asynchronous programming


### Future and Generic Types

**Future Interface**: Represents the result of an asynchronous computation[^3].

```java
public interface Future<T> {
    T get();                    // Blocks until result is available
    T get(long timeout, TimeUnit unit);  // Blocks with timeout
    boolean isDone();           // Check if computation is complete
    boolean cancel(boolean mayInterruptIfRunning);  // Cancel computation
}
```

**Generic Type Benefits:**

- **Type Safety**: Compile-time type checking
- **No Casting**: Eliminates need for explicit casting
- **Clear API**: Method signatures clearly indicate return types

**Example: Before and After Generics**

```java
// Without Generics (Old Approach)
Object call() {
    return "Hello World";
}
Object result = future.get();
String message = (String) result;  // Casting required, runtime risk

// With Generics (Modern Approach)
String call() {
    return "Hello World";
}
String result = future.get();  // No casting needed, compile-time safety
```


## Practical Implementation: Merge Sort with Threads

### Algorithm Overview

Merge sort is perfect for parallel implementation due to its divide-and-conquer nature[^1].

**Sequential Merge Sort Process:**

```
Original Array: [8, 1, 6, 2, 3, 9, 7, 5]

Step 1: Divide
[8, 1, 6, 2] | [3, 9, 7, 5]

Step 2: Recursive Division
[8, 1] [6, 2] | [3, 9] [7, 5]
[^8] [^1] [^6] [^2] | [^3] [^9] [^7] [^5]

Step 3: Merge Back
[1, 8] [2, 6] | [3, 9] [5, 7]
[1, 2, 6, 8] | [3, 5, 7, 9]
[1, 2, 3, 5, 6, 7, 8, 9]
```


### Sequential vs Parallel Approach

**Sequential Approach:**

- Single thread processes entire array
- Time Complexity: O(n log n)
- Space Complexity: O(n)

**Parallel Approach:**

- Multiple threads handle different sub-arrays simultaneously
- Potential for O(log n) time with O(n) processors
- Better resource utilization


### Complete Implementation

**Client.java**

```java
import java.util.concurrent.*;
import java.util.*;

public class Client {
    public static void main(String[] args) throws ExecutionException, InterruptedException {
        // Input array to be sorted
        List<Integer> list = List.of(8, 1, 6, 2, 3, 9, 7, 5);
        
        // Create sorter instance
        Sorter arraySorter = new Sorter(list);
        
        // Create thread pool with 4 threads
        ExecutorService ex = Executors.newFixedThreadPool(4);
        
        // Submit sorting task and get Future
        Future<List<Integer>> sortedArrayFuture = ex.submit(arraySorter);
        
        // Block and wait for result
        List<Integer> sortedArray = sortedArrayFuture.get();
        
        // Print sorted result
        System.out.println(sortedArray);
        
        // Clean shutdown
        ex.shutdown();
    }
}
```

**Sorter.java**

```java
import java.util.concurrent.*;
import java.util.*;

public class Sorter implements Callable<List<Integer>> {
    private List<Integer> arrayToSort;
    
    public Sorter(List<Integer> arrayToSort) {
        this.arrayToSort = arrayToSort;
    }
    
    @Override
    public List<Integer> call() throws Exception {
        // Base case: single element is already sorted
        if (arrayToSort.size() == 1) {
            return arrayToSort;
        }
        
        // Divide phase
        int mid = arrayToSort.size() / 2;
        List<Integer> leftArray = new ArrayList<>();
        List<Integer> rightArray = new ArrayList<>();
        
        // Split array into two halves
        for (int i = 0; i < mid; i++) {
            leftArray.add(arrayToSort.get(i));
        }
        for (int i = mid; i < arrayToSort.size(); i++) {
            rightArray.add(arrayToSort.get(i));
        }
        
        // Create sorter instances for sub-arrays
        Sorter leftSorter = new Sorter(leftArray);
        Sorter rightSorter = new Sorter(rightArray);
        
        // Create executor for parallel processing
        ExecutorService ex = Executors.newFixedThreadPool(10);
        
        // Submit both sorting tasks in parallel
        Future<List<Integer>> leftArrayFuture = ex.submit(leftSorter);
        Future<List<Integer>> rightArrayFuture = ex.submit(rightSorter);
        
        // Wait for both results
        List<Integer> sortedLeftArray = leftArrayFuture.get();
        List<Integer> sortedRightArray = rightArrayFuture.get();
        
        // Merge phase
        List<Integer> result = merge(sortedLeftArray, sortedRightArray);
        
        // Cleanup
        ex.shutdown();
        
        return result;
    }
    
    /**
     * Merges two sorted arrays into one sorted array
     */
    private List<Integer> merge(List<Integer> left, List<Integer> right) {
        List<Integer> result = new ArrayList<>();
        int i = 0, j = 0;
        
        // Merge elements while both arrays have elements
        while (i < left.size() && j < right.size()) {
            if (left.get(i) <= right.get(j)) {
                result.add(left.get(i));
                i++;
            } else {
                result.add(right.get(j));
                j++;
            }
        }
        
        // Add remaining elements from left array
        while (i < left.size()) {
            result.add(left.get(i));
            i++;
        }
        
        // Add remaining elements from right array
        while (j < right.size()) {
            result.add(right.get(j));
            j++;
        }
        
        return result;
    }
}
```

**Execution Flow Visualization:**

```
Thread Pool (4 threads)
├── Main Thread: [8,1,6,2,3,9,7,5]
├── Thread-1: [8,1,6,2] → Thread-3: [8,1] + Thread-4: [6,2]
├── Thread-2: [3,9,7,5] → Thread-5: [3,9] + Thread-6: [7,5]
└── Merge Results: [1,2,3,5,6,7,8,9]
```


## Thread Pool Configuration and Best Practices

### ThreadPoolExecutor Parameters

For fine-grained control, use ThreadPoolExecutor directly[^2][^5][^6]:

```java
ThreadPoolExecutor executor = new ThreadPoolExecutor(
    corePoolSize,      // Minimum number of threads
    maximumPoolSize,   // Maximum number of threads
    keepAliveTime,     // Thread idle timeout
    timeUnit,          // Time unit for keepAliveTime
    workQueue,         // Queue for holding tasks
    threadFactory,     // Factory for creating threads
    rejectionHandler   // Handler for rejected tasks
);
```

**Parameter Explanation:**


| Parameter | Description | Example Value |
| :-- | :-- | :-- |
| **corePoolSize** | Minimum threads always alive | 2 |
| **maximumPoolSize** | Maximum threads allowed | 4 |
| **keepAliveTime** | Idle timeout for excess threads | 10 seconds |
| **workQueue** | Task queue implementation | ArrayBlockingQueue(2) |
| **rejectionHandler** | What to do when queue is full | Custom handler |

### Monitoring Thread Pools

**Custom Monitor Implementation:**

```java
public class ThreadPoolMonitor implements Runnable {
    private ThreadPoolExecutor executor;
    private int seconds;
    private boolean running = true;
    
    public ThreadPoolMonitor(ThreadPoolExecutor executor, int delay) {
        this.executor = executor;
        this.seconds = delay;
    }
    
    @Override
    public void run() {
        while (running) {
            System.out.printf(
                "[Monitor] Pool: %d/%d, Active: %d, Completed: %d, Tasks: %d%n",
                executor.getPoolSize(),
                executor.getCorePoolSize(),
                executor.getActiveCount(),
                executor.getCompletedTaskCount(),
                executor.getTaskCount()
            );
            
            try {
                Thread.sleep(seconds * 1000);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                break;
            }
        }
    }
    
    public void shutdown() {
        this.running = false;
    }
}
```


### Rejection Handling

**Custom Rejection Handler:**

```java
public class CustomRejectionHandler implements RejectedExecutionHandler {
    @Override
    public void rejectedExecution(Runnable task, ThreadPoolExecutor executor) {
        System.err.println("Task " + task.toString() + " rejected from " + 
                          executor.toString());
        
        // Options for handling rejection:
        // 1. Log and discard
        // 2. Execute in caller thread
        // 3. Add to alternative queue
        // 4. Throw exception
    }
}
```

**Built-in Rejection Policies:**

- **AbortPolicy**: Throws RejectedExecutionException (default)
- **CallerRunsPolicy**: Executes task in caller thread
- **DiscardPolicy**: Silently discards the task
- **DiscardOldestPolicy**: Discards oldest task and retries

**Best Practices:**

1. **Size pools appropriately**: Generally, core pool size = number of CPU cores
2. **Monitor performance**: Use monitoring tools to track pool metrics
3. **Handle rejections gracefully**: Implement appropriate rejection handling
4. **Shutdown properly**: Always call shutdown() to release resources
5. **Use bounded queues**: Prevent memory issues with unbounded queues

This comprehensive approach to thread pools and parallel programming forms the foundation for building scalable, efficient applications in production environments.

<div style="text-align: center">⁂</div>

[^1]: Writingmultithreaded.pdf

[^2]: https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html

[^3]: https://www.scaler.com/topics/callable-interface-in-java/

[^4]: https://natalieagus.github.io/50005/os/java-sync

[^5]: https://www.alibabacloud.com/blog/java-development-practices-using-thread-pools-and-thread-variables-properly_600180

[^6]: https://www.digitalocean.com/community/tutorials/threadpoolexecutor-java-thread-pool-example-executorservice

[^7]: https://dzone.com/articles/deep-dive-into-java-executorservice

[^8]: https://softwaremill.com/threadpools-executors-and-java/

[^9]: https://www.cs.tufts.edu/comp/150CCP/lectures/Lecture23.pdf

[^10]: https://www.codingshuttle.com/spring-boot-handbook/multi-threading-java-executor-framework

[^11]: https://www.w3resource.com/java-exercises/java-interface-exercise-11.php

